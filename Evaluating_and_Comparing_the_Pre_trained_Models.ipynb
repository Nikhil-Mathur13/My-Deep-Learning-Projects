{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PDjawYfIf5fj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1.0/255,\n",
        "#     rotation_range=30,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     validation_split=0.2  # Split for validation\n",
        "# )\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     '\\content\\concrete_crack_images_for_classification.zip',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical',\n",
        "#     subset='training'\n",
        "# )\n",
        "\n",
        "# validation_generator = train_datagen.flow_from_directory(\n",
        "#     '\\content\\concrete_crack_images_for_classification.zip',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical',\n",
        "#     subset='validation'\n",
        "# )\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     '\\content\\concrete_crack_images_for_classification.zip',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='categorical',\n",
        "#     shuffle=False\n",
        "# )\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Assuming your zip file is in the current working directory\n",
        "zip_file_path = '/content/concrete_crack_images_for_classification.zip'  # Correct the path if needed\n",
        "extract_dir = '/content/extracted_images'  # Choose a directory for extraction\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Update the directory path in your ImageDataGenerator calls\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    extract_dir,  # Use the extracted directory\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    extract_dir,  # Use the extracted directory\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    extract_dir,  # Use the extracted directory\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "3jshh-b-ggp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model without the top layer (include_top=False)\n",
        "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model_vgg16.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "wMicUOoEgl7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom layers on top of the base model\n",
        "x = Flatten()(base_model_vgg16.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "vgg16_model = Model(inputs=base_model_vgg16.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "iAkeFNekgn88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_vgg16 = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "l3tizSFngoz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model (for testing purposes)\n",
        "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x_resnet = Flatten()(base_model_resnet50.output)\n",
        "x_resnet = Dense(256, activation='relu')(x_resnet)\n",
        "x_resnet = Dropout(0.5)(x_resnet)\n",
        "output_resnet = Dense(train_generator.num_classes, activation='softmax')(x_resnet)\n",
        "resnet50_model = Model(inputs=base_model_resnet50.input, outputs=output_resnet)\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "6H0nde4egsRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate VGG16 model\n",
        "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate(test_generator)\n",
        "print(f\"VGG16 Test Accuracy: {vgg16_test_accuracy:.2f}\")\n",
        "\n",
        "# Evaluate ResNet50 model\n",
        "resnet50_test_loss, resnet50_test_accuracy = resnet50_model.evaluate(test_generator)\n",
        "print(f\"ResNet50 Test Accuracy: {resnet50_test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "ZQhLxvhogs6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions with VGG16\n",
        "vgg16_predictions = vgg16_model.predict(test_generator)\n",
        "vgg16_predicted_classes = vgg16_predictions.argmax(axis=1)\n"
      ],
      "metadata": {
        "id": "vfZEQyE_gutq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions with ResNet50\n",
        "resnet50_predictions = resnet50_model.predict(test_generator)\n",
        "resnet50_predicted_classes = resnet50_predictions.argmax(axis=1)\n"
      ],
      "metadata": {
        "id": "zjNmpg6qgwx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compare the predictions of VGG16 and ResNet50\n",
        "comparison = np.equal(vgg16_predicted_classes, resnet50_predicted_classes)\n",
        "print(f\"Number of matching predictions: {np.sum(comparison)} / {len(comparison)}\")\n"
      ],
      "metadata": {
        "id": "Bv85RcCxgyKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}